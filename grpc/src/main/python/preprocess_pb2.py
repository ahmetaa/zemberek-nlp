# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: preprocess.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='preprocess.proto',
  package='zemberek.preprocessor',
  syntax='proto3',
  serialized_pb=_b('\n\x10preprocess.proto\x12\x15zemberek.preprocessor\"D\n\x13TokenizationRequest\x12\r\n\x05input\x18\x01 \x01(\t\x12\x1e\n\x16includeTokenBoundaries\x18\x02 \x01(\x08\"@\n\x05Token\x12\r\n\x05token\x18\x01 \x01(\t\x12\x0c\n\x04type\x18\x02 \x01(\t\x12\r\n\x05start\x18\x03 \x01(\x05\x12\x0b\n\x03\x65nd\x18\x04 \x01(\x05\"D\n\x14TokenizationResponse\x12,\n\x06tokens\x18\x01 \x03(\x0b\x32\x1c.zemberek.preprocessor.Token\"-\n\x19SentenceExtractionRequest\x12\x10\n\x08\x64ocument\x18\x01 \x01(\t\"/\n\x1aSentenceExtractionResponse\x12\x11\n\tsentences\x18\x01 \x03(\t2\xf4\x01\n\x14PreprocessingService\x12\x63\n\x08Tokenize\x12*.zemberek.preprocessor.TokenizationRequest\x1a+.zemberek.preprocessor.TokenizationResponse\x12w\n\x10\x45xtractSentences\x12\x30.zemberek.preprocessor.SentenceExtractionRequest\x1a\x31.zemberek.preprocessor.SentenceExtractionResponseB\x12\n\x0ezemberek.protoP\x01\x62\x06proto3')
)




_TOKENIZATIONREQUEST = _descriptor.Descriptor(
  name='TokenizationRequest',
  full_name='zemberek.preprocessor.TokenizationRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='input', full_name='zemberek.preprocessor.TokenizationRequest.input', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='includeTokenBoundaries', full_name='zemberek.preprocessor.TokenizationRequest.includeTokenBoundaries', index=1,
      number=2, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=43,
  serialized_end=111,
)


_TOKEN = _descriptor.Descriptor(
  name='Token',
  full_name='zemberek.preprocessor.Token',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='token', full_name='zemberek.preprocessor.Token.token', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='type', full_name='zemberek.preprocessor.Token.type', index=1,
      number=2, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='start', full_name='zemberek.preprocessor.Token.start', index=2,
      number=3, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='end', full_name='zemberek.preprocessor.Token.end', index=3,
      number=4, type=5, cpp_type=1, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=113,
  serialized_end=177,
)


_TOKENIZATIONRESPONSE = _descriptor.Descriptor(
  name='TokenizationResponse',
  full_name='zemberek.preprocessor.TokenizationResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='tokens', full_name='zemberek.preprocessor.TokenizationResponse.tokens', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=179,
  serialized_end=247,
)


_SENTENCEEXTRACTIONREQUEST = _descriptor.Descriptor(
  name='SentenceExtractionRequest',
  full_name='zemberek.preprocessor.SentenceExtractionRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='document', full_name='zemberek.preprocessor.SentenceExtractionRequest.document', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=249,
  serialized_end=294,
)


_SENTENCEEXTRACTIONRESPONSE = _descriptor.Descriptor(
  name='SentenceExtractionResponse',
  full_name='zemberek.preprocessor.SentenceExtractionResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='sentences', full_name='zemberek.preprocessor.SentenceExtractionResponse.sentences', index=0,
      number=1, type=9, cpp_type=9, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=296,
  serialized_end=343,
)

_TOKENIZATIONRESPONSE.fields_by_name['tokens'].message_type = _TOKEN
DESCRIPTOR.message_types_by_name['TokenizationRequest'] = _TOKENIZATIONREQUEST
DESCRIPTOR.message_types_by_name['Token'] = _TOKEN
DESCRIPTOR.message_types_by_name['TokenizationResponse'] = _TOKENIZATIONRESPONSE
DESCRIPTOR.message_types_by_name['SentenceExtractionRequest'] = _SENTENCEEXTRACTIONREQUEST
DESCRIPTOR.message_types_by_name['SentenceExtractionResponse'] = _SENTENCEEXTRACTIONRESPONSE
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

TokenizationRequest = _reflection.GeneratedProtocolMessageType('TokenizationRequest', (_message.Message,), dict(
  DESCRIPTOR = _TOKENIZATIONREQUEST,
  __module__ = 'preprocess_pb2'
  # @@protoc_insertion_point(class_scope:zemberek.preprocessor.TokenizationRequest)
  ))
_sym_db.RegisterMessage(TokenizationRequest)

Token = _reflection.GeneratedProtocolMessageType('Token', (_message.Message,), dict(
  DESCRIPTOR = _TOKEN,
  __module__ = 'preprocess_pb2'
  # @@protoc_insertion_point(class_scope:zemberek.preprocessor.Token)
  ))
_sym_db.RegisterMessage(Token)

TokenizationResponse = _reflection.GeneratedProtocolMessageType('TokenizationResponse', (_message.Message,), dict(
  DESCRIPTOR = _TOKENIZATIONRESPONSE,
  __module__ = 'preprocess_pb2'
  # @@protoc_insertion_point(class_scope:zemberek.preprocessor.TokenizationResponse)
  ))
_sym_db.RegisterMessage(TokenizationResponse)

SentenceExtractionRequest = _reflection.GeneratedProtocolMessageType('SentenceExtractionRequest', (_message.Message,), dict(
  DESCRIPTOR = _SENTENCEEXTRACTIONREQUEST,
  __module__ = 'preprocess_pb2'
  # @@protoc_insertion_point(class_scope:zemberek.preprocessor.SentenceExtractionRequest)
  ))
_sym_db.RegisterMessage(SentenceExtractionRequest)

SentenceExtractionResponse = _reflection.GeneratedProtocolMessageType('SentenceExtractionResponse', (_message.Message,), dict(
  DESCRIPTOR = _SENTENCEEXTRACTIONRESPONSE,
  __module__ = 'preprocess_pb2'
  # @@protoc_insertion_point(class_scope:zemberek.preprocessor.SentenceExtractionResponse)
  ))
_sym_db.RegisterMessage(SentenceExtractionResponse)


DESCRIPTOR.has_options = True
DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\n\016zemberek.protoP\001'))

_PREPROCESSINGSERVICE = _descriptor.ServiceDescriptor(
  name='PreprocessingService',
  full_name='zemberek.preprocessor.PreprocessingService',
  file=DESCRIPTOR,
  index=0,
  options=None,
  serialized_start=346,
  serialized_end=590,
  methods=[
  _descriptor.MethodDescriptor(
    name='Tokenize',
    full_name='zemberek.preprocessor.PreprocessingService.Tokenize',
    index=0,
    containing_service=None,
    input_type=_TOKENIZATIONREQUEST,
    output_type=_TOKENIZATIONRESPONSE,
    options=None,
  ),
  _descriptor.MethodDescriptor(
    name='ExtractSentences',
    full_name='zemberek.preprocessor.PreprocessingService.ExtractSentences',
    index=1,
    containing_service=None,
    input_type=_SENTENCEEXTRACTIONREQUEST,
    output_type=_SENTENCEEXTRACTIONRESPONSE,
    options=None,
  ),
])
_sym_db.RegisterServiceDescriptor(_PREPROCESSINGSERVICE)

DESCRIPTOR.services_by_name['PreprocessingService'] = _PREPROCESSINGSERVICE

# @@protoc_insertion_point(module_scope)
